{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Day profiles from seasonal profiles\n",
    "Please extract the seasonal data from CKW's monthly data as done in CKW.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import glob\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\spring\\\\0_spring_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\spring\\\\10000_spring_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\spring\\\\10001_spring_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\spring\\\\10002_spring_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\spring\\\\10003_spring_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\spring\\\\10004_spring_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\spring\\\\10005_spring_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\spring\\\\10006_spring_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\spring\\\\10007_spring_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\spring\\\\10008_spring_data.csv']\n"
     ]
    }
   ],
   "source": [
    "#load spring files first\n",
    "# Function to extract numeric part from file name\n",
    "season= \"spring\"\n",
    "def extract_numeric_part(file_path):\n",
    "    match = re.search(rf'(\\d+)_{season}_data\\.csv', file_path)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    else:\n",
    "        print(f\"Warning: Filename {file_path} does not match pattern\")\n",
    "        return None\n",
    "\n",
    "# Get the list of file paths\n",
    "file_paths = glob.glob(rf'C:\\Users\\pana\\Desktop\\DATA\\ckw\\2021\\{season}\\*_{season}_data.csv') #location of spring season files\n",
    "file_paths = sorted(file_paths[:10], key=extract_numeric_part)\n",
    "print(file_paths[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def week_extraction(file_path):\n",
    "    \"\"\" This function extracts the energy consumption data per days of the week from the season\"\"\"\n",
    "    \n",
    "    # Load the data into a Polars DataFrame\n",
    "    data = pl.read_csv(file_path)\n",
    "\n",
    "    # Ensure the timestamp column is treated as a string\n",
    "    data = data.with_columns(pl.col('timestamp').cast(pl.Utf8))\n",
    "    #print(data, \"1\")\n",
    "    # Parse the timestamp column to datetime with the correct format and strict=False\n",
    "    data = data.with_columns(pl.col('timestamp').str.strptime(pl.Datetime, \"%Y-%m-%dT%H:%M:%S%.fZ\", strict=False))\n",
    "    #print(data, \"2\")\n",
    "    # Extract the day of the week and the time of day from the timestamp\n",
    "    data = data.with_columns([\n",
    "        pl.col('timestamp').dt.strftime('%Y-%m-%d').alias('date'),\n",
    "        pl.col('timestamp').dt.weekday().alias('day_of_week'),\n",
    "        pl.col('timestamp').dt.strftime('%H:%M:%S').alias('time_of_day')\n",
    "    ])\n",
    "    #print(data, \"3\")\n",
    "\n",
    "    # Group by day of the week and time of day\n",
    "    grouped = data.group_by(['day_of_week', 'time_of_day'])\n",
    "\n",
    "    # Calculate the mean for each group\n",
    "    daily_averages = grouped.agg(pl.col('value_kwh').mean().alias('average_kwh'))\n",
    "    #print(data,\"3\")\n",
    "    # Pivot the data to have days of the week as columns and time of day as rows\n",
    "    pivot_table = daily_averages.pivot(\n",
    "        values='average_kwh',\n",
    "        index='time_of_day',\n",
    "        columns='day_of_week'\n",
    "    ).sort('time_of_day')\n",
    "\n",
    "    # Replace the day_of_week index with actual day names\n",
    "    day_mapping = {1: 'Monday', 2: 'Tuesday', 3: 'Wednesday', 4: 'Thursday', 5: 'Friday', 6: 'Saturday', 7:'Sunday'}\n",
    "    pivot_table = pivot_table.rename({str(day): name for day, name in day_mapping.items()})\n",
    "    #pivot_table= pivot_table.with_columns(pl.lit(f'{season}').alias('season'))\n",
    "    #print(f'{season} table',pivot_table)\n",
    "    # Show the resulting pivot table\n",
    "    return(pivot_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated week profiles from spring: 0/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pana\\AppData\\Local\\Temp\\ipykernel_33308\\338265271.py:26: DeprecationWarning: The argument `columns` for `DataFrame.pivot` is deprecated. It has been renamed to `on`.\n",
      "  pivot_table = daily_averages.pivot(\n"
     ]
    }
   ],
   "source": [
    "#saves the average week for each household in the 'week' folder\n",
    "for idx,file_path in enumerate(file_paths):\n",
    "    #print(idx,file_path)\n",
    "    df = week_extraction(file_path)\n",
    "    df.write_csv(rf'C:\\Users\\pana\\Desktop\\DATA\\ckw\\2022\\week\\{idx}_week_data.csv') #path were the file will be saved\n",
    "    if idx%1000 == 0:\n",
    "        print(f\"generated week profiles from {season}: {idx}/{len(file_paths)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2022\\\\week\\\\0_week_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2022\\\\week\\\\1_week_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2022\\\\week\\\\2_week_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2022\\\\week\\\\3_week_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2022\\\\week\\\\4_week_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2022\\\\week\\\\5_week_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2022\\\\week\\\\6_week_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2022\\\\week\\\\7_week_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2022\\\\week\\\\8_week_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2022\\\\week\\\\9_week_data.csv']\n"
     ]
    }
   ],
   "source": [
    "def extract_numeric_part(file_path):\n",
    "    match = re.search(rf'(\\d+)_week_data\\.csv', file_path)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    else:\n",
    "        print(f\"Warning: Filename {file_path} does not match pattern\")\n",
    "        return None\n",
    "\n",
    "# Get the list of file paths\n",
    "file_paths = glob.glob(rf'C:\\Users\\pana\\Desktop\\DATA\\ckw\\2021\\week\\*_week_data.csv') #same path as before\n",
    "file_paths = sorted(file_paths, key=extract_numeric_part)\n",
    "print(file_paths[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\summer\\\\0_summer_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\summer\\\\10000_summer_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\summer\\\\10001_summer_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\summer\\\\10002_summer_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\summer\\\\10003_summer_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\summer\\\\10004_summer_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\summer\\\\10005_summer_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\summer\\\\10006_summer_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\summer\\\\10007_summer_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\summer\\\\10008_summer_data.csv']\n"
     ]
    }
   ],
   "source": [
    "season= \"summer\"\n",
    "def extract_numeric_part(file_path):\n",
    "    match = re.search(rf'(\\d+)_{season}_data\\.csv', file_path)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    else:\n",
    "        print(f\"Warning: Filename {file_path} does not match pattern\")\n",
    "        return None\n",
    "    \n",
    "#path were summer season files are\n",
    "toadd_file_paths = glob.glob(rf'C:\\Users\\pana\\Desktop\\DATA\\ckw\\2021\\{season}\\*_{season}_data.csv') \n",
    "toadd_file_paths = sorted(toadd_file_paths[:10], key=extract_numeric_part)\n",
    "print(toadd_file_paths[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added summer week data to previous seasons 0/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pana\\AppData\\Local\\Temp\\ipykernel_33308\\338265271.py:26: DeprecationWarning: The argument `columns` for `DataFrame.pivot` is deprecated. It has been renamed to `on`.\n",
      "  pivot_table = daily_averages.pivot(\n"
     ]
    }
   ],
   "source": [
    "def append_season_week(existing_file_path, summer_file_path):\n",
    "    \"\"\" This function adds the week profile of the next season to the existing week profile\"\"\"\n",
    "    # Load existing data into a Polars DataFrame\n",
    "    existing_data = pl.read_csv(existing_file_path)\n",
    "    #print(\"existing data\", existing_data)\n",
    "\n",
    "    # Load summer data\n",
    "    table_summer = week_extraction(summer_file_path)\n",
    "    #print(table_summer)\n",
    "    # Ensure columns match between existing_data and pivot_table_summer\n",
    "    existing_data = existing_data.select(table_summer.columns)\n",
    "\n",
    "    # Concatenate existing data with summer pivot_table\n",
    "    concatenated_data = pl.concat([existing_data, table_summer])\n",
    "\n",
    "    # Return the concatenated DataFrame\n",
    "    return concatenated_data\n",
    "\n",
    "\n",
    "for i,file_path in enumerate(file_paths):\n",
    "   \n",
    "    existing_file = file_path\n",
    "    summer_file = toadd_file_paths[i]\n",
    "    #print(summer_file,existing_file)\n",
    "    result = append_season_week(existing_file, summer_file)\n",
    "\n",
    "    # Print or save the result\n",
    "    result.write_csv(rf'C:\\Users\\pana\\Desktop\\DATA\\ckw\\2021\\week\\{i}_week_data.csv')\n",
    "    if i%1000 == 0:\n",
    "        print(f\"Added {season} week data to previous seasons {i}/{len(file_paths)} done \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\autumn\\\\0_autumn_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\autumn\\\\10000_autumn_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\autumn\\\\10001_autumn_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\autumn\\\\10002_autumn_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\autumn\\\\10003_autumn_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\autumn\\\\10004_autumn_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\autumn\\\\10005_autumn_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\autumn\\\\10006_autumn_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\autumn\\\\10007_autumn_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\autumn\\\\10008_autumn_data.csv']\n",
      "Added autumn week data to previous seasons 0/10 done \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pana\\AppData\\Local\\Temp\\ipykernel_33308\\338265271.py:26: DeprecationWarning: The argument `columns` for `DataFrame.pivot` is deprecated. It has been renamed to `on`.\n",
      "  pivot_table = daily_averages.pivot(\n"
     ]
    }
   ],
   "source": [
    "season= \"autumn\"\n",
    "def extract_numeric_part(file_path):\n",
    "    match = re.search(rf'(\\d+)_{season}_data\\.csv', file_path)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    else:\n",
    "        print(f\"Warning: Filename {file_path} does not match pattern\")\n",
    "        return None\n",
    "    \n",
    "#path were summer season files are\n",
    "toadd_file_paths = glob.glob(rf'C:\\Users\\pana\\Desktop\\DATA\\ckw\\2021\\{season}\\*_{season}_data.csv') \n",
    "toadd_file_paths = sorted(toadd_file_paths[:10], key=extract_numeric_part)\n",
    "print(toadd_file_paths[:10])\n",
    "\n",
    "for i,file_path in enumerate(file_paths):\n",
    "   \n",
    "    existing_file = file_path\n",
    "    summer_file = toadd_file_paths[i]\n",
    "    #print(summer_file,existing_file)\n",
    "    result = append_season_week(existing_file, summer_file)\n",
    "\n",
    "    # Print or save the result\n",
    "    result.write_csv(rf'C:\\Users\\pana\\Desktop\\DATA\\ckw\\2021\\week\\{i}_week_data.csv')\n",
    "    if i%1000 == 0:\n",
    "        print(f\"Added {season} week data to previous seasons {i}/{len(file_paths)} done \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\winter\\\\0_winter_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\winter\\\\10000_winter_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\winter\\\\10001_winter_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\winter\\\\10002_winter_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\winter\\\\10003_winter_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\winter\\\\10004_winter_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\winter\\\\10005_winter_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\winter\\\\10006_winter_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\winter\\\\10007_winter_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\winter\\\\10008_winter_data.csv']\n",
      "Added winter week data to previous seasons 0/10 done \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pana\\AppData\\Local\\Temp\\ipykernel_33308\\338265271.py:26: DeprecationWarning: The argument `columns` for `DataFrame.pivot` is deprecated. It has been renamed to `on`.\n",
      "  pivot_table = daily_averages.pivot(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' The files saved contain week profiles of spring, summer, autumn and winter, total with 386 rows'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "season= \"winter\"\n",
    "def extract_numeric_part(file_path):\n",
    "    match = re.search(rf'(\\d+)_{season}_data\\.csv', file_path)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    else:\n",
    "        print(f\"Warning: Filename {file_path} does not match pattern\")\n",
    "        return None\n",
    "    \n",
    "#path were summer season files are\n",
    "toadd_file_paths = glob.glob(rf'C:\\Users\\pana\\Desktop\\DATA\\ckw\\2021\\{season}\\*_{season}_data.csv') \n",
    "toadd_file_paths = sorted(toadd_file_paths[:10], key=extract_numeric_part)\n",
    "print(toadd_file_paths[:10])\n",
    "\n",
    "for i,file_path in enumerate(file_paths):\n",
    "   \n",
    "    existing_file = file_path\n",
    "    summer_file = toadd_file_paths[i]\n",
    "    #print(summer_file,existing_file)\n",
    "    result = append_season_week(existing_file, summer_file)\n",
    "\n",
    "    # Print or save the result\n",
    "    result.write_csv(rf'C:\\Users\\pana\\Desktop\\DATA\\ckw\\2021\\week\\{i}_week_data.csv')\n",
    "    if i%1000 == 0:\n",
    "        print(f\"Added {season} week data to previous seasons {i}/{len(file_paths)} done \")\n",
    "\"\"\" The files saved contain week profiles of spring, summer, autumn and winter, total with 385 rows\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Week avg and normalized day columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_order = ['time_of_day', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "\n",
    "def week_avg(data):\n",
    "    df= data\n",
    "    #df = df[standard_order]\n",
    "    df = df.with_columns(\n",
    "        #weekdays_avg = pl.mean_horizontal(\"Monday\",\"Tuesday\",\"Wednesday\",\"Thursday\",\"Friday\")\n",
    "        #weekend_avg = pl.mean_horizontal(\"Saturday\",\"Sunday\")\n",
    "        week_avg = pl.mean_horizontal(\"Monday\",\"Tuesday\",\"Wednesday\",\"Thursday\",\"Friday\", \"Saturday\", \"Sunday\")\n",
    "        )\n",
    "    max_df= df.select(pl.max(\"week_avg\"))\n",
    "    max_df= max_df['week_avg'][0]\n",
    "    \n",
    "    if max_df ==0:\n",
    "        df = df.with_columns(\n",
    "            normalized_day = pl.col(\"week_avg\") \n",
    "            #normalized day is the representative normalized day profile of each household\n",
    "        )\n",
    "    else:\n",
    "        df = df.with_columns(\n",
    "            normalized_day = pl.col(\"week_avg\")/max_df\n",
    "        )\n",
    "\n",
    "    df = df.sort(\"time_of_day\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0/10\n"
     ]
    }
   ],
   "source": [
    "# Function to process each file\n",
    "def process_file(df):\n",
    "    \"\"\" This function groups by the time of day for each day of the week\"\"\"\n",
    "    # Group by the 'time' column and calculate the mean for each group\n",
    "    grouped_df = df.group_by(\"time_of_day\").agg([\n",
    "        pl.mean(\"Monday\").alias(\"Monday\"),\n",
    "        pl.mean(\"Tuesday\").alias(\"Tuesday\"),\n",
    "        pl.mean(\"Wednesday\").alias(\"Wednesday\"),\n",
    "        pl.mean(\"Thursday\").alias(\"Thursday\"),\n",
    "        pl.mean(\"Friday\").alias(\"Friday\"),\n",
    "        pl.mean(\"Saturday\").alias(\"Saturday\"),\n",
    "        pl.mean(\"Sunday\").alias(\"Sunday\")\n",
    "    ])\n",
    "\n",
    "    return grouped_df\n",
    "\n",
    "#saves the average week for each household in the 'week' folder\n",
    "for idx,file_path in enumerate(file_paths):\n",
    "    df = pl.read_csv(file_path)\n",
    "    df = df[standard_order]\n",
    "    #df = df.with_columns(pl.col('time_of_day').str.strptime(pl.Datetime, \"%Y-%m-%dT%H:%M:%S%.fZ\", strict=False))\n",
    "    \n",
    "    df_reduced = process_file(df)\n",
    "    \n",
    "    df_normalized = week_avg(df_reduced)\n",
    "    \n",
    "    df_normalized.write_csv(rf'C:\\Users\\pana\\Desktop\\DATA\\ckw\\2022\\week\\{idx}_week_data.csv')\n",
    "    if idx%1000 == 0:\n",
    "        print(f\"Processed {idx}/{len(file_paths)}\")\n",
    "\n",
    "#Average week profiles for the whole year is processed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
