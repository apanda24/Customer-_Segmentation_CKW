{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Weekday and Weekend profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import glob\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weekday profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\spring\\\\0_spring_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\spring\\\\10000_spring_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\spring\\\\10001_spring_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\spring\\\\10002_spring_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\spring\\\\10003_spring_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\spring\\\\10004_spring_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\spring\\\\10005_spring_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\spring\\\\10006_spring_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\spring\\\\10007_spring_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\spring\\\\10008_spring_data.csv']\n"
     ]
    }
   ],
   "source": [
    "#load spring files first\n",
    "# Function to extract numeric part from file name\n",
    "season= \"spring\"\n",
    "def extract_numeric_part(file_path):\n",
    "    match = re.search(rf'(\\d+)_{season}_data\\.csv', file_path)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    else:\n",
    "        print(f\"Warning: Filename {file_path} does not match pattern\")\n",
    "        return None\n",
    "\n",
    "# Get the list of file paths\n",
    "file_paths = glob.glob(rf'C:\\Users\\pana\\Desktop\\DATA\\ckw\\2021\\{season}\\*_{season}_data.csv') #location of spring season files\n",
    "file_paths = sorted(file_paths, key=extract_numeric_part)\n",
    "print(file_paths[:5]) #check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add the holiday dates to exclude\n",
    "def weekday_extraction(file_path):\n",
    "    \"\"\" This function extracts weekday data from the seasonal files.\n",
    "         Update the holidays_to_exclude to remove the holidays from weekdays\"\"\"\n",
    "    # Load the data into a Polars DataFrame\n",
    "    data = pl.read_csv(file_path)\n",
    "\n",
    "    # Ensure the timestamp column is treated as a string\n",
    "    data = data.with_columns(pl.col('timestamp').cast(pl.Utf8))\n",
    "    #print(data, \"1\")\n",
    "    # Parse the timestamp column to datetime with the correct format and strict=False\n",
    "    data = data.with_columns(pl.col('timestamp').str.strptime(pl.Datetime, \"%Y-%m-%dT%H:%M:%S%.fZ\", strict=False))\n",
    "    #print(data, \"2\")\n",
    "    # Extract the day of the week and the time of day from the timestamp\n",
    "    data = data.with_columns([\n",
    "        pl.col('timestamp').dt.strftime('%Y-%m-%d').alias('date'),\n",
    "        pl.col('timestamp').dt.weekday().alias('day_of_week'),\n",
    "        pl.col('timestamp').dt.strftime('%H:%M:%S').alias('time_of_day'),\n",
    "        pl.lit('spring').alias('season')\n",
    "    ])\n",
    "    #print(data, \"3\")\n",
    "\n",
    "    # Filter out weekends (Monday=1, ..., Sunday=7)\n",
    "    weekdays = [1, 2, 3, 4,5]\n",
    "    data = data.filter(pl.col('day_of_week').is_in(weekdays))\n",
    "\n",
    "    # Define holidays to exclude\n",
    "    holidays_to_exclude = ['2021-06-03', '2021-04-05', '2021-05-13']\n",
    "    #holidays_to_exclude = ['2022-01-01']\n",
    "    # Filter out holidays\n",
    "    data = data.filter(~pl.col('date').is_in(holidays_to_exclude))\n",
    "\n",
    "    # Group by day of the week and time of day\n",
    "    grouped = data.group_by(['day_of_week', 'time_of_day'])\n",
    "\n",
    "    # Calculate the mean for each group\n",
    "    daily_averages = grouped.agg(pl.col('value_kwh').mean().alias('average_kwh'))\n",
    "    #print(data,\"3\")\n",
    "    # Pivot the data to have days of the week as columns and time of day as rows\n",
    "    pivot_table = daily_averages.pivot(\n",
    "        values='average_kwh',\n",
    "        index='time_of_day',\n",
    "        columns='day_of_week'\n",
    "    ).sort('time_of_day')\n",
    "\n",
    "    # Replace the day_of_week index with actual day names\n",
    "    day_mapping = {1: 'Monday', 2: 'Tuesday', 3: 'Wednesday', 4: 'Thursday', 5: 'Friday'}\n",
    "    pivot_table = pivot_table.rename({str(day): name for day, name in day_mapping.items()})\n",
    "    #pivot_table= pivot_table.with_columns(pl.lit(f'{season}').alias('season')) #if you want a column with season name\n",
    "    #print(f'{season} table',pivot_table)\n",
    "    # Show the resulting pivot table\n",
    "    return(pivot_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spring weekday files generated 0 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pana\\AppData\\Local\\Temp\\ipykernel_13980\\3692816435.py:40: DeprecationWarning: The argument `columns` for `DataFrame.pivot` is deprecated. It has been renamed to `on`.\n",
      "  pivot_table = daily_averages.pivot(\n"
     ]
    }
   ],
   "source": [
    "for idx,file_path in enumerate(file_paths):\n",
    "   \n",
    "    weekdays_df = weekday_extraction(file_path)\n",
    "\n",
    "    # saving the files. update path\n",
    "    weekdays_df.write_csv(rf'C:\\Users\\pana\\Desktop\\DATA\\ckw\\2022\\weekdays\\{idx}_weekdays_data.csv')\n",
    "\n",
    "    if idx%1000 ==0:\n",
    "        print(f\"{season} weekday files generated {idx} of {len(file_paths)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2022\\\\weekdays\\\\0_weekdays_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2022\\\\weekdays\\\\1_weekdays_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2022\\\\weekdays\\\\2_weekdays_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2022\\\\weekdays\\\\3_weekdays_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2022\\\\weekdays\\\\4_weekdays_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2022\\\\weekdays\\\\5_weekdays_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2022\\\\weekdays\\\\6_weekdays_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2022\\\\weekdays\\\\7_weekdays_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2022\\\\weekdays\\\\8_weekdays_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2022\\\\weekdays\\\\9_weekdays_data.csv']\n"
     ]
    }
   ],
   "source": [
    "def extract_numeric_part(file_path):\n",
    "    match = re.search(rf'(\\d+)_weekdays_data\\.csv', file_path)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    else:\n",
    "        print(f\"Warning: Filename {file_path} does not match pattern\")\n",
    "        return None\n",
    "\n",
    "# Get the list of file paths\n",
    "file_paths = glob.glob(rf'C:\\Users\\pana\\Desktop\\DATA\\ckw\\2022\\weekdays\\*_weekdays_data.csv') #same path as before\n",
    "file_paths = sorted(file_paths, key=extract_numeric_part)\n",
    "print(file_paths[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\summer\\\\0_summer_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\summer\\\\10000_summer_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\summer\\\\10001_summer_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\summer\\\\10002_summer_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\summer\\\\10003_summer_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\summer\\\\10004_summer_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\summer\\\\10005_summer_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\summer\\\\10006_summer_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\summer\\\\10007_summer_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\summer\\\\10008_summer_data.csv']\n"
     ]
    }
   ],
   "source": [
    "season= \"summer\"\n",
    "def extract_numeric_part(file_path):\n",
    "    match = re.search(rf'(\\d+)_{season}_data\\.csv', file_path)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    else:\n",
    "        print(f\"Warning: Filename {file_path} does not match pattern\")\n",
    "        return None\n",
    "    \n",
    "#path were summer season files are\n",
    "toadd_file_paths = glob.glob(rf'C:\\Users\\pana\\Desktop\\DATA\\ckw\\2021\\{season}\\*_{season}_data.csv') \n",
    "toadd_file_paths = sorted(toadd_file_paths, key=extract_numeric_part)\n",
    "print(toadd_file_paths[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summer weekday files add to existing weekday file 0 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pana\\AppData\\Local\\Temp\\ipykernel_13980\\3692816435.py:40: DeprecationWarning: The argument `columns` for `DataFrame.pivot` is deprecated. It has been renamed to `on`.\n",
      "  pivot_table = daily_averages.pivot(\n"
     ]
    }
   ],
   "source": [
    "def append_season_weekday_averages(existing_file_path, summer_file_path):\n",
    "    # Load existing data into a Polars DataFrame\n",
    "    existing_data = pl.read_csv(existing_file_path)\n",
    "    #print(\"existing data\", existing_data)\n",
    "\n",
    "    # Load summer data\n",
    "    table_summer = weekday_extraction(summer_file_path)\n",
    "    \n",
    "    # Ensure columns match between existing_data and pivot_table_summer\n",
    "    existing_data = existing_data.select(table_summer.columns)\n",
    "\n",
    "    # Concatenate existing data with summer pivot_table\n",
    "    concatenated_data = pl.concat([existing_data, table_summer])\n",
    "\n",
    "    # Return the concatenated DataFrame\n",
    "    return concatenated_data\n",
    "\n",
    "for idx,file_path in enumerate(file_paths):\n",
    "   \n",
    "    existing_file = file_path\n",
    "    summer_file = toadd_file_paths[i]\n",
    "    #print(summer_file,existing_file)\n",
    "    result = append_season_weekday_averages(existing_file, summer_file)\n",
    "\n",
    "    # Print or save the result\n",
    "    result.write_csv(rf'C:\\Users\\pana\\Desktop\\DATA\\ckw\\2022\\weekdays\\{idx}_weekdays_data.csv')\n",
    "\n",
    "    if idx%1000 ==0:\n",
    "        print(f\"{season} weekday files add to existing weekday file {idx} of {len(file_paths)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\autumn\\\\0_autumn_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\autumn\\\\10000_autumn_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\autumn\\\\10001_autumn_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\autumn\\\\10002_autumn_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\autumn\\\\10003_autumn_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\autumn\\\\10004_autumn_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\autumn\\\\10005_autumn_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\autumn\\\\10006_autumn_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\autumn\\\\10007_autumn_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\autumn\\\\10008_autumn_data.csv']\n",
      "autumn weekday files add to existing weekday file 0 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pana\\AppData\\Local\\Temp\\ipykernel_13980\\3692816435.py:40: DeprecationWarning: The argument `columns` for `DataFrame.pivot` is deprecated. It has been renamed to `on`.\n",
      "  pivot_table = daily_averages.pivot(\n"
     ]
    }
   ],
   "source": [
    "season= \"autumn\"\n",
    "def extract_numeric_part(file_path):\n",
    "    match = re.search(rf'(\\d+)_{season}_data\\.csv', file_path)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    else:\n",
    "        print(f\"Warning: Filename {file_path} does not match pattern\")\n",
    "        return None\n",
    "    \n",
    "#path were summer season files are\n",
    "toadd_file_paths = glob.glob(rf'C:\\Users\\pana\\Desktop\\DATA\\ckw\\2021\\{season}\\*_{season}_data.csv') \n",
    "toadd_file_paths = sorted(toadd_file_paths, key=extract_numeric_part)\n",
    "print(toadd_file_paths[:5])\n",
    "\n",
    "for idx,file_path in enumerate(file_paths):\n",
    "   \n",
    "    existing_file = file_path\n",
    "    summer_file = toadd_file_paths[i]\n",
    "    \n",
    "    result = append_season_weekday_averages(existing_file, summer_file)\n",
    "\n",
    "    # Print or save the result\n",
    "    result.write_csv(rf'C:\\Users\\pana\\Desktop\\DATA\\ckw\\2022\\weekdays\\{idx}_weekdays_data.csv')\n",
    "\n",
    "    if idx%1000 ==0:\n",
    "        print(f\"{season} weekday files add to existing weekday file {idx} of {len(file_paths)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\winter\\\\0_winter_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\winter\\\\10000_winter_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\winter\\\\10001_winter_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\winter\\\\10002_winter_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\winter\\\\10003_winter_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\winter\\\\10004_winter_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\winter\\\\10005_winter_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\winter\\\\10006_winter_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\winter\\\\10007_winter_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\winter\\\\10008_winter_data.csv']\n",
      "winter weekday files add to existing weekday file 0 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pana\\AppData\\Local\\Temp\\ipykernel_13980\\3692816435.py:40: DeprecationWarning: The argument `columns` for `DataFrame.pivot` is deprecated. It has been renamed to `on`.\n",
      "  pivot_table = daily_averages.pivot(\n"
     ]
    }
   ],
   "source": [
    "season= \"winter\"\n",
    "def extract_numeric_part(file_path):\n",
    "    match = re.search(rf'(\\d+)_{season}_data\\.csv', file_path)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    else:\n",
    "        print(f\"Warning: Filename {file_path} does not match pattern\")\n",
    "        return None\n",
    "    \n",
    "#path were summer season files are\n",
    "toadd_file_paths = glob.glob(rf'C:\\Users\\pana\\Desktop\\DATA\\ckw\\2021\\{season}\\*_{season}_data.csv') \n",
    "toadd_file_paths = sorted(toadd_file_paths, key=extract_numeric_part)\n",
    "print(f\" the {season} files are:\",toadd_file_paths[:5])\n",
    "\n",
    "for idx,file_path in enumerate(file_paths):\n",
    "   \n",
    "    existing_file = file_path\n",
    "    summer_file = toadd_file_paths[i]\n",
    "    \n",
    "    result = append_season_weekday_averages(existing_file, summer_file)\n",
    "\n",
    "    # Print or save the result\n",
    "    result.write_csv(rf'C:\\Users\\pana\\Desktop\\DATA\\ckw\\2022\\weekdays\\{idx}_weekdays_data.csv')\n",
    "\n",
    "    if idx%1000 ==0:\n",
    "        print(f\"{season} weekday files add to existing weekday file {idx} of {len(file_paths)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_order = ['time_of_day', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday']\n",
    "\n",
    "def weekdays_avg(df):\n",
    "    \n",
    "    #df = df[standard_order]\n",
    "    df = df.with_columns(\n",
    "        weekdays_avg = pl.mean_horizontal(\"Monday\",\"Tuesday\",\"Wednesday\",\"Thursday\",\"Friday\")\n",
    "        )\n",
    "    max_df= df.select(pl.max(\"weekdays_avg\"))\n",
    "    max_df= max_df['weekdays_avg'][0]\n",
    "    #print(max_df)\n",
    "    if max_df ==0:\n",
    "        df = df.with_columns(\n",
    "            normalized_weekdays = pl.col(\"weekdays_avg\")\n",
    "        )\n",
    "    else:\n",
    "        df = df.with_columns(\n",
    "            normalized_weekdays = pl.col(\"weekdays_avg\")/max_df\n",
    "        )\n",
    "\n",
    "    df = df.sort(\"time_of_day\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0/10\n"
     ]
    }
   ],
   "source": [
    "# Function to process each file\n",
    "def process_file(df):\n",
    "    \"\"\" This function groups by the time of day for each day of the week\"\"\"\n",
    "    # Group by the 'time' column and calculate the mean for each group\n",
    "    grouped_df = df.group_by(\"time_of_day\").agg([\n",
    "        pl.mean(\"Monday\").alias(\"Monday\"),\n",
    "        pl.mean(\"Tuesday\").alias(\"Tuesday\"),\n",
    "        pl.mean(\"Wednesday\").alias(\"Wednesday\"),\n",
    "        pl.mean(\"Thursday\").alias(\"Thursday\"),\n",
    "        pl.mean(\"Friday\").alias(\"Friday\")\n",
    "    ])\n",
    "\n",
    "    return grouped_df\n",
    "\n",
    "#saves the average week for each household in the 'week' folder\n",
    "for idx,file_path in enumerate(file_paths):\n",
    "    df = pl.read_csv(file_path)\n",
    "    df = df[standard_order]\n",
    "    #df = df.with_columns(pl.col('time_of_day').str.strptime(pl.Datetime, \"%Y-%m-%dT%H:%M:%S%.fZ\", strict=False))\n",
    "    \n",
    "    df_reduced = process_file(df)\n",
    "    \n",
    "    df_normalized = weekdays_avg(df_reduced)\n",
    "    \n",
    "    df_normalized.write_csv(rf'C:\\Users\\pana\\Desktop\\DATA\\ckw\\2022\\weekdays\\{idx}_weekdays_data.csv')\n",
    "    if idx%1000 == 0:\n",
    "        print(f\"Processed {idx}/{len(file_paths)}\")\n",
    "\n",
    "#Average week profiles for the whole year is processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weekend Profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\spring\\\\0_spring_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\spring\\\\10000_spring_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\spring\\\\10001_spring_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\spring\\\\10002_spring_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\spring\\\\10003_spring_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\spring\\\\10004_spring_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\spring\\\\10005_spring_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\spring\\\\10006_spring_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\spring\\\\10007_spring_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\spring\\\\10008_spring_data.csv']\n"
     ]
    }
   ],
   "source": [
    "#load spring files first\n",
    "# Function to extract numeric part from file name\n",
    "season= \"spring\"\n",
    "def extract_numeric_part(file_path):\n",
    "    match = re.search(rf'(\\d+)_{season}_data\\.csv', file_path)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    else:\n",
    "        print(f\"Warning: Filename {file_path} does not match pattern\")\n",
    "        return None\n",
    "\n",
    "# Get the list of file paths\n",
    "file_paths = glob.glob(rf'C:\\Users\\pana\\Desktop\\DATA\\ckw\\2021\\{season}\\*_{season}_data.csv') #location of spring season files\n",
    "file_paths = sorted(file_paths, key=extract_numeric_part)\n",
    "print(f\"{seasonal} files location:\",file_paths[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weekend_extraction(file_path):\n",
    "    # Load the data into a Polars DataFrame\n",
    "    data = pl.read_csv(file_path)\n",
    "\n",
    "    # Ensure the timestamp column is treated as a string\n",
    "    data = data.with_columns(pl.col('timestamp').cast(pl.Utf8))\n",
    "\n",
    "    # Parse the timestamp column to datetime with the correct format and strict=False\n",
    "    data = data.with_columns(pl.col('timestamp').str.strptime(pl.Datetime, \"%Y-%m-%dT%H:%M:%S%.fZ\", strict=False))\n",
    "\n",
    "    # Extract the day of the week and the time of day from the timestamp\n",
    "    data = data.with_columns([\n",
    "        pl.col('timestamp').dt.strftime('%Y-%m-%d').alias('date'),\n",
    "        pl.col('timestamp').dt.weekday().alias('day_of_week'),\n",
    "        pl.col('timestamp').dt.strftime('%H:%M:%S').alias('time_of_day'),\n",
    "        pl.lit('spring').alias('season')\n",
    "    ])\n",
    "    #print(data, \"2\")\n",
    "\n",
    "    # Filter out weekends (Monday=1, ..., Sunday=7)\n",
    "    weekend = [6,7]\n",
    "    data = data.filter(pl.col('day_of_week').is_in(weekend))\n",
    "\n",
    "    # Group by day of the week and time of day\n",
    "    grouped = data.group_by(['day_of_week', 'time_of_day'])\n",
    "\n",
    "    # Calculate the mean for each group\n",
    "    daily_averages = grouped.agg(pl.col('value_kwh').mean().alias('average_kwh'))\n",
    "\n",
    "    # Pivot the data to have days of the week as columns and time of day as rows\n",
    "    pivot_table = daily_averages.pivot(\n",
    "        values='average_kwh',\n",
    "        index='time_of_day',\n",
    "        columns='day_of_week'\n",
    "    ).sort('time_of_day')\n",
    "\n",
    "    # Replace the day_of_week index with actual day names\n",
    "    day_mapping = {6: 'Saturday', 7: 'Sunday'}\n",
    "    pivot_table = pivot_table.rename({str(day): name for day, name in day_mapping.items()})\n",
    "    #pivot_table= pivot_table.with_columns(pl.lit(f'{season}').alias('season')) #if you want a column with season name,\n",
    "\n",
    "    #print(f'{season} table',pivot_table)\n",
    "    \n",
    "    return(pivot_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spring weekday files generated 0 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pana\\AppData\\Local\\Temp\\ipykernel_13980\\2303263902.py:31: DeprecationWarning: The argument `columns` for `DataFrame.pivot` is deprecated. It has been renamed to `on`.\n",
      "  pivot_table = daily_averages.pivot(\n"
     ]
    }
   ],
   "source": [
    "for idx,file_path in enumerate(file_paths):\n",
    "   \n",
    "    weekend_df = weekend_extraction(file_path)\n",
    "\n",
    "    # saving the files. update path\n",
    "    weekend_df.write_csv(rf'C:\\Users\\pana\\Desktop\\DATA\\ckw\\2022\\weekend\\{idx}_weekend_data.csv')\n",
    "\n",
    "    if idx%1000 ==0:\n",
    "        print(f\"{season} weekday files generated {idx} of {len(file_paths)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2022\\\\weekend\\\\0_weekend_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2022\\\\weekend\\\\1_weekend_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2022\\\\weekend\\\\2_weekend_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2022\\\\weekend\\\\3_weekend_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2022\\\\weekend\\\\4_weekend_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2022\\\\weekend\\\\5_weekend_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2022\\\\weekend\\\\6_weekend_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2022\\\\weekend\\\\7_weekend_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2022\\\\weekend\\\\8_weekend_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2022\\\\weekend\\\\9_weekend_data.csv']\n"
     ]
    }
   ],
   "source": [
    "def extract_numeric_part(file_path):\n",
    "    match = re.search(rf'(\\d+)_weekend_data\\.csv', file_path)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    else:\n",
    "        print(f\"Warning: Filename {file_path} does not match pattern\")\n",
    "        return None\n",
    "\n",
    "# Get the list of file paths\n",
    "file_paths = glob.glob(rf'C:\\Users\\pana\\Desktop\\DATA\\ckw\\2022\\weekend\\*_weekend_data.csv') #same path as previous cell\n",
    "file_paths = sorted(file_paths, key=extract_numeric_part)\n",
    "print(file_paths[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_order = ['time_of_day','Saturday','Sunday'] #add 'season' here if you have a column with season names\n",
    "def weekend_avg(data):\n",
    "    df= data\n",
    "    df = df[standard_order]\n",
    "    df = df.with_columns(\n",
    "        weekend_avg = pl.mean_horizontal(\"Saturday\",\"Sunday\")\n",
    "        )\n",
    "    max_df= df.select(pl.max(\"weekend_avg\"))\n",
    "    max_df= max_df['weekend_avg'][0]\n",
    "    #print(max_df)\n",
    "    if max_df ==0:\n",
    "        df = df.with_columns(\n",
    "            normalized_weekend = pl.col(\"weekend_avg\")\n",
    "        )\n",
    "    else:\n",
    "        df = df.with_columns(\n",
    "            normalized_weekend = pl.col(\"weekend_avg\")/max_df\n",
    "        )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\summer\\\\0_summer_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\summer\\\\10000_summer_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\summer\\\\10001_summer_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\summer\\\\10002_summer_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\summer\\\\10003_summer_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\summer\\\\10004_summer_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\summer\\\\10005_summer_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\summer\\\\10006_summer_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\summer\\\\10007_summer_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\summer\\\\10008_summer_data.csv']\n"
     ]
    }
   ],
   "source": [
    "season= \"summer\"\n",
    "def extract_numeric_part(file_path):\n",
    "    match = re.search(rf'(\\d+)_{season}_data\\.csv', file_path)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    else:\n",
    "        print(f\"Warning: Filename {file_path} does not match pattern\")\n",
    "        return None\n",
    "    \n",
    "#path were summer season files are\n",
    "toadd_file_paths = glob.glob(rf'C:\\Users\\pana\\Desktop\\DATA\\ckw\\2021\\{season}\\*_{season}_data.csv') \n",
    "toadd_file_paths = sorted(toadd_file_paths, key=extract_numeric_part)\n",
    "print(toadd_file_paths[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summer weekday files generated 0 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pana\\AppData\\Local\\Temp\\ipykernel_13980\\2303263902.py:31: DeprecationWarning: The argument `columns` for `DataFrame.pivot` is deprecated. It has been renamed to `on`.\n",
      "  pivot_table = daily_averages.pivot(\n"
     ]
    }
   ],
   "source": [
    "def append_season_weekend_averages(existing_file_path, summer_file_path):\n",
    "    # Load existing data into a Polars DataFrame\n",
    "    existing_data = pl.read_csv(existing_file_path)\n",
    "    existing_data = existing_data[standard_order]\n",
    "    #print(\"existing data\", existing_data)\n",
    "\n",
    "    # Load summer data\n",
    "    table_summer = weekend_extraction(summer_file_path)\n",
    "    #print(\"table_summer\",table_summer)\n",
    "    table_summer = table_summer[standard_order]\n",
    "    \n",
    "    # Ensure columns match between existing_data and pivot_table_summer\n",
    "    existing_data = existing_data.select(table_summer.columns)\n",
    "\n",
    "    # Concatenate existing data with summer pivot_table\n",
    "    concatenated_data = pl.concat([existing_data, table_summer])\n",
    "\n",
    "    # Return the concatenated DataFrame\n",
    "    return concatenated_data\n",
    "\n",
    "# Example usage:\n",
    "for idx,file_path in enumerate(file_paths):\n",
    "    existing_file = file_path\n",
    "    summer_file = toadd_file_paths[i]\n",
    "    #print(summer_file,existing_file)\n",
    "    result = append_season_weekend_averages(existing_file, summer_file)\n",
    "\n",
    "    # Print or save the result\n",
    "    result.write_csv(rf'C:\\Users\\pana\\Desktop\\DATA\\ckw\\2022\\weekend\\{idx}_weekend_data.csv')\n",
    "    if idx%1000 ==0:\n",
    "        print(f\"{season} weekday files generated {idx} of {len(file_paths)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\autumn\\\\0_autumn_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\autumn\\\\10000_autumn_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\autumn\\\\10001_autumn_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\autumn\\\\10002_autumn_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\autumn\\\\10003_autumn_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\autumn\\\\10004_autumn_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\autumn\\\\10005_autumn_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\autumn\\\\10006_autumn_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\autumn\\\\10007_autumn_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\autumn\\\\10008_autumn_data.csv']\n",
      "autumn weekday files add to existing weekday file 0 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pana\\AppData\\Local\\Temp\\ipykernel_13980\\2303263902.py:31: DeprecationWarning: The argument `columns` for `DataFrame.pivot` is deprecated. It has been renamed to `on`.\n",
      "  pivot_table = daily_averages.pivot(\n"
     ]
    }
   ],
   "source": [
    "season= \"autumn\"\n",
    "def extract_numeric_part(file_path):\n",
    "    match = re.search(rf'(\\d+)_{season}_data\\.csv', file_path)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    else:\n",
    "        print(f\"Warning: Filename {file_path} does not match pattern\")\n",
    "        return None\n",
    "    \n",
    "#path were summer season files are\n",
    "toadd_file_paths = glob.glob(rf'C:\\Users\\pana\\Desktop\\DATA\\ckw\\2021\\{season}\\*_{season}_data.csv') \n",
    "toadd_file_paths = sorted(toadd_file_paths, key=extract_numeric_part)\n",
    "print(toadd_file_paths[:5])\n",
    "\n",
    "for idx,file_path in enumerate(file_paths):\n",
    "   \n",
    "    existing_file = file_path\n",
    "    summer_file = toadd_file_paths[i]\n",
    "    \n",
    "    result = append_season_weekend_averages(existing_file, summer_file)\n",
    "\n",
    "    # Print or save the result\n",
    "    result.write_csv(rf'C:\\Users\\pana\\Desktop\\DATA\\ckw\\2022\\weekend\\{idx}_weekend_data.csv')\n",
    "\n",
    "    if idx%1000 ==0:\n",
    "        print(f\"{season} weekday files add to existing weekday file {idx} of {len(file_paths)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\winter\\\\0_winter_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\winter\\\\10000_winter_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\winter\\\\10001_winter_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\winter\\\\10002_winter_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\winter\\\\10003_winter_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\winter\\\\10004_winter_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\winter\\\\10005_winter_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\winter\\\\10006_winter_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\winter\\\\10007_winter_data.csv', 'C:\\\\Users\\\\pana\\\\Desktop\\\\DATA\\\\ckw\\\\2021\\\\winter\\\\10008_winter_data.csv']\n",
      "winter weekend files added to existing weekend file 0 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pana\\AppData\\Local\\Temp\\ipykernel_13980\\2303263902.py:31: DeprecationWarning: The argument `columns` for `DataFrame.pivot` is deprecated. It has been renamed to `on`.\n",
      "  pivot_table = daily_averages.pivot(\n"
     ]
    }
   ],
   "source": [
    "season= \"winter\"\n",
    "def extract_numeric_part(file_path):\n",
    "    match = re.search(rf'(\\d+)_{season}_data\\.csv', file_path)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    else:\n",
    "        print(f\"Warning: Filename {file_path} does not match pattern\")\n",
    "        return None\n",
    "    \n",
    "#path were summer season files are\n",
    "toadd_file_paths = glob.glob(rf'C:\\Users\\pana\\Desktop\\DATA\\ckw\\2021\\{season}\\*_{season}_data.csv') \n",
    "toadd_file_paths = sorted(toadd_file_paths, key=extract_numeric_part)\n",
    "print(toadd_file_paths[:5])\n",
    "\n",
    "for idx,file_path in enumerate(file_paths):\n",
    "   \n",
    "    existing_file = file_path\n",
    "    summer_file = toadd_file_paths[i]\n",
    "    \n",
    "    result = append_season_weekend_averages(existing_file, summer_file)\n",
    "\n",
    "    # Print or save the result\n",
    "    result.write_csv(rf'C:\\Users\\pana\\Desktop\\DATA\\ckw\\2022\\weekend\\{idx}_weekend_data.csv')\n",
    "\n",
    "    if idx%1000 ==0:\n",
    "        print(f\"{season} weekend files added to existing weekend file {idx} of {len(file_paths)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0/10\n"
     ]
    }
   ],
   "source": [
    "# Function to process each file\n",
    "def process_file(df):\n",
    "    \"\"\" This function groups by the time of day for each day of the week\"\"\"\n",
    "    # Group by the 'time' column and calculate the mean for each group\n",
    "    grouped_df = df.group_by(\"time_of_day\").agg([\n",
    "        pl.mean(\"Saturday\").alias(\"Saturday\"),\n",
    "        pl.mean(\"Sunday\").alias(\"Sunday\")\n",
    "    ])\n",
    "\n",
    "    return grouped_df\n",
    "\n",
    "#saves the average week for each household in the 'week' folder\n",
    "for idx,file_path in enumerate(file_paths):\n",
    "    df = pl.read_csv(file_path)\n",
    "    df = df[standard_order]\n",
    "    #df = df.with_columns(pl.col('time_of_day').str.strptime(pl.Datetime, \"%Y-%m-%dT%H:%M:%S%.fZ\", strict=False))\n",
    "    \n",
    "    df_reduced = process_file(df)\n",
    "    \n",
    "    df_normalized = weekend_avg(df_reduced)\n",
    "    \n",
    "    df_normalized.write_csv(rf'C:\\Users\\pana\\Desktop\\DATA\\ckw\\2022\\weekend\\{idx}_weekend_data.csv')\n",
    "    if idx%1000 == 0:\n",
    "        print(f\"Processed {idx}/{len(file_paths)}\")\n",
    "\n",
    "print(\"weekend files generated\")\n",
    "#Average week profiles for the whole year is processed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
